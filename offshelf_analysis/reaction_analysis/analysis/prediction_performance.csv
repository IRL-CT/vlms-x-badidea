model,accuracy,precision,recall,f1_score
llama32vision,0.43333333333333335,0.43333333333333335,1.0,0.6046511627906976
gemma3,0.43333333333333335,0.43333333333333335,1.0,0.6046511627906976
qwen25,0.5,0.42857142857142855,0.46153846153846156,0.4444444444444444
gemma3_27b,0.43333333333333335,0.43333333333333335,1.0,0.6046511627906976
llava,0.3333333333333333,0.36,0.6923076923076923,0.47368421052631576
