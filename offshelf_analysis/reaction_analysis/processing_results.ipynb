{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing results from different VLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local VLMs for scenario prediction (from frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#go through all files that start with 'results_', then turn it into a pandas dataframe, \n",
    "# #then put everything into a single df where the prediction if the mode of the frames\n",
    "def load_results(directory):\n",
    "    results = pd.DataFrame()\n",
    "    full_results = pd.DataFrame()\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.startswith('results_'):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            df = pd.read_csv(filepath)\n",
    "            #add column in the beginning with the filename without 'results_' and '.csv'\n",
    "            df['model'] = filename[8:-4]\n",
    "            #make it first column\n",
    "            df = df[['model'] + [col for col in df.columns if col != 'model']]\n",
    "\n",
    "            #group by video_name and take the mode of the predictions\n",
    "            df_grouped = df.groupby('video_name').agg(lambda x: x.mode()[0] if not x.mode().empty else np.nan).reset_index()\n",
    "            #add the grouped dataframe to the full results\n",
    "            full_results = pd.concat([full_results, df_grouped], ignore_index=True)\n",
    "\n",
    "            results = pd.concat([results, df], ignore_index=True)\n",
    "\n",
    "    #group by filename, by video, and take the mode of the predictions\n",
    "\n",
    "    return results, full_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           model  video_name\n",
      "0         gemma3          30\n",
      "1     gemma3_27b          30\n",
      "2  llama32vision           9\n",
      "3          llava          30\n",
      "4         qwen25          30\n"
     ]
    }
   ],
   "source": [
    "path = '.'\n",
    "results, full_results = load_results(path)\n",
    "#save the results to a csv file\n",
    "results.to_csv('all_predictions.csv', index=False)\n",
    "#save the full results to a csv file\n",
    "full_results.to_csv('all_predictions_grouped.csv', index=False)\n",
    "\n",
    "#see how many unique videos are for each model\n",
    "unique_videos_per_model = results.groupby('model')['video_name'].nunique().reset_index()\n",
    "print(unique_videos_per_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: llama32vision\n",
      "  Poorly: 9\n",
      "  Well: 0\n",
      "Model: gemma3\n",
      "  Poorly: 30\n",
      "  Well: 0\n",
      "Model: qwen25\n",
      "  Poorly: 14\n",
      "  Well: 16\n",
      "Model: gemma3_27b\n",
      "  Poorly: 30\n",
      "  Well: 0\n",
      "Model: llava\n",
      "  Poorly: 25\n",
      "  Well: 5\n"
     ]
    }
   ],
   "source": [
    "#now, per model, print how many videos are \"Poorly\" and how many are \"Well\", accounting for small variations in the writing\n",
    "for model in full_results['model'].unique():\n",
    "    print(f\"Model: {model}\")\n",
    "    model_results = full_results[full_results['model'] == model]\n",
    "    poorly_count = model_results['outcome_prediction'].str.contains('Poorly', case=False, na=False).sum()\n",
    "    well_count = model_results['outcome_prediction'].str.contains('Well', case=False, na=False).sum()\n",
    "    print(f\"  Poorly: {poorly_count}\")\n",
    "    print(f\"  Well: {well_count}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ollama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
