model,accuracy,precision,recall,f1_score
llama32vision,0.43333333333333335,0.43333333333333335,1.0,0.6046511627906976
llavallama3,0.5333333333333333,0.4,0.15384615384615385,0.2222222222222222
gemma3,0.43333333333333335,0.43333333333333335,1.0,0.6046511627906976
qwen25,0.5,0.42857142857142855,0.46153846153846156,0.4444444444444444
gemma3_27b,0.43333333333333335,0.43333333333333335,1.0,0.6046511627906976
llava,0.3333333333333333,0.36,0.6923076923076923,0.47368421052631576
